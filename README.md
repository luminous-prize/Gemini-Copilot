# Gemini-Copilot

üöÄ Dynamic Co-Pilot with Gemini-Flash 1.5

This project leverages the power of Gemini-flash 1.5 to create a co-pilot that integrates with custom API calls, returning JSON data, parsing it, and displaying it seamlessly back to the user.

#### What‚Äôs Inside?
‚úîÔ∏è Interactive Chatbot: A dynamic and responsive chatbot powered by LLM's function-calling API.
‚úîÔ∏è Custom API Integration: Easily integrate your own set of observability APIs to create tailored solutions.
‚úîÔ∏è Flask-Based Web Application: A lightweight, hosted web app for smooth deployment and usability.

#### What You Need?
1. Your set of observability APIs.
2. A Google API key to utilize the Gemini-flash 1.5 model.

#### Why Use This?
This project is ideal for anyone with APIs looking to harness the potential of large language models to build a dynamic, interactive assistant. Whether it‚Äôs for monitoring, reporting, or any custom application, this co-pilot makes the process efficient and user-friendly.

#### Get Started

Clone the repo, plug in your APIs and API key, and watch your co-pilot come to life!
## Work-Flow
![C816F61E-02C7-4525-99AF-254918C33AA5_1_201_a](https://github.com/user-attachments/assets/3922775e-d360-4df7-883c-2ec4c749fc67)

## Bot
![81FD00EE-C111-479F-899E-3003C2308AEC_1_201_a](https://github.com/user-attachments/assets/0ff97d38-fa69-49a9-9021-6522a29d3a6a)
